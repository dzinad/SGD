{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Генерация случайных входных данных\n",
    " Сгенерируем 2k (2000) случайных точек: k из них лежат на прямой y = x -1, остальные k на прямой y = x + 1, x &isin; [-bound; bound] ([-200; 200]) Добавим гауссовский шум. Первой группе точек присвоим метку 1, второй -1. Создадим соответствующие массивы, объединим их в один. Разобьем выборку на обучающую и тестовую в соотношении 4:1. Так как по построению массивов x и y точки из разных групп распределены по всему массиву равномерно, то просто возьмем в качестве тестовой выборки последнюю пятую часть точек."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def f1(x):\n",
    "    return x + 1\n",
    "\n",
    "def f2(x):\n",
    "    return x - 1\n",
    "\n",
    "\n",
    "k = 1000\n",
    "bound = 200\n",
    "\n",
    "noise1 = np.random.normal(size = k, scale = 0.95)        \n",
    "noise2 = np.random.normal(size = k, scale = 0.95)        \n",
    "x1 = np.random.randint(-1 * bound, bound, k)\n",
    "y1 = f1(x1) + noise1\n",
    "x2 = np.random.randint(-1 * bound, bound, k)\n",
    "y2 = f2(x2) + noise2\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "for i in range(0, k):\n",
    "    x.append([x1[i], y1[i]])\n",
    "    y.append(1)\n",
    "    x.append([x2[i], y2[i]])\n",
    "    y.append(-1)\n",
    "\n",
    "    \n",
    "x_train = x[:int(k * 0.8)]\n",
    "x_test = x[int(k * 0.8) + 1:]\n",
    "y_train = y[:int(k * 0.8)]\n",
    "y_test = y[int(k * 0.8) + 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Создание классификатора\n",
    "Создадим бинарный линейный классификатор, который будет минимизировать функцию потерь HingeLoss: hl(x) = max(0, 1 - y &lowast; a(x)), где a(x) = &lt;w, x&gt; (x с добавленным в конец столбцом единиц). Минимизируем при этом только на тех иксах, которые дают неправильный ответ: для этого выбираем индексы i, для которых 1 - y[i] &lowast; a(x[i]) &gt; 0. В результате будет получен вектор весов w размерности n + 1, если на вход поступали n-мерные точки. Уравнение разделяющей плоскости при этом будет выглядеть следующим образом: w<sub>1</sub> &lowast; x<sub>1</sub> + w<sub>2</sub> &lowast; x<sub>2</sub> + ... + w<sub>n</sub> &lowast; x<sub>n</sub> + w<sub>n + 1</sub> = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import linalg as la\n",
    "from random import randint\n",
    "\n",
    "class DClassifier(object):\n",
    "    \"\"\"docstring\"\"\"\n",
    " \n",
    "    def __init__(self, eps = 0.01):\n",
    "        \"\"\"Constructor\"\"\"\n",
    "        self.eps = eps\n",
    "        self.iter = 1\n",
    "    \n",
    "    def grad(self, x, y):\n",
    "        return -1. * y * x\n",
    "\n",
    "    def fit(self, x_arr, y_arr):\n",
    "        self.iter = 1\n",
    "        x = np.array(x_arr)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        l = x.shape[0]\n",
    "        x_expanded = np.hstack((x, np.ones((l, 1))))\n",
    "        d = x.shape[1]\n",
    "        y = np.array(y_arr)\n",
    "        self.w = np.zeros(d + 1)\n",
    "        c = 0.5        \n",
    "    \n",
    "        while True:\n",
    "            bad_indices = []\n",
    "            for i in range (0, l):\n",
    "                if y[i] * np.dot(x_expanded[i], self.w) < 1:\n",
    "                    bad_indices.append(i)\n",
    "            if len(bad_indices) == 0:\n",
    "                break\n",
    "            if len(bad_indices) == 1:\n",
    "                index = 0\n",
    "            else:\n",
    "                index = randint(0, len(bad_indices) - 1)\n",
    "            g = grad(x_expanded[bad_indices[index]], y[bad_indices[index]])\n",
    "            tmp = g * c / self.iter\n",
    "            prev = self.w\n",
    "            self.w = self.w - tmp\n",
    "            if (la.norm(self.w - prev) <= self.eps):\n",
    "                break\n",
    "            self.iter += 1\n",
    "\n",
    "    def get_iter_count(self):\n",
    "        return self.iter\n",
    "        \n",
    "    def predict(self, x_arr):\n",
    "        arr = []\n",
    "        x_expanded = np.hstack((x_arr, np.ones((len(x_arr), 1))))\n",
    "        for i in range(0, len(x_expanded)):\n",
    "            if (np.dot(x_expanded[i], self.w) >= 0):\n",
    "                arr.append(1)\n",
    "            else:\n",
    "                arr.append(-1)\n",
    "        return arr\n",
    "    \n",
    "    def graph2D(self, x, y):\n",
    "        x = np.array(x)\n",
    "        x1 = np.array([])\n",
    "        y1 = np.array([])\n",
    "        x2 = np.array([])\n",
    "        y2 = np.array([])\n",
    "        x_div = np.linspace(-1 * bound, bound, bound / 4)\n",
    "        y_div = 1. * (-1 * np.linspace(self.w[2], self.w[2], num = len(x_div)) - self.w[0] * x_div) / self.w[1]\n",
    "        for i in range (0, len(x)):\n",
    "            if y[i] == 1:\n",
    "                x1 = np.append(x1, x[i][0])\n",
    "                y1 = np.append(y1, x[i][1])\n",
    "            if y[i] == -1:\n",
    "                x2 = np.append(x2, x[i][0])\n",
    "                y2 = np.append(y2, x[i][1])\n",
    "        plt.scatter(x1, y1, c = 'red', s = 10, alpha = 0.2)\n",
    "        plt.scatter(x2, y2, c = 'yellow', s = 10, alpha = 0.2)\n",
    "        plt.plot(x_div, y_div, c = 'blue')\n",
    "        plt.show()               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Использование классификатора\n",
    "\n",
    "Обучим классификатор на обучающей выборке и попробуем использовать его для тестовой. Ответы запишем в переменную test1.\n",
    "Затем воспользуемся стандартным классификатором sklearn.linear_model.SGDClassifier, обучим его на той же обучающей выборке и проверим на той же тестовой. Результаты запишем в переменную test2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = DClassifier()\n",
    "clf1.fit(x_train, y_train)\n",
    "test1 = clf1.predict(x_test)\n",
    "\n",
    "from sklearn import linear_model\n",
    "clf2 = linear_model.SGDClassifier()\n",
    "clf2.fit(x_train, y_train)\n",
    "test2 = clf2.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сравнение результатов\n",
    "\n",
    "Сначала сравним результаты работы написанного классификатора и стандартного.\n",
    "Результаты различаются от запуска к запуску. Иногда совпадает более, чем на 80%, ногда менее, чем на 50. Бывают случаи, когда совпадение менее 10 процентов. Интересное наблюдение: тогда каждый из классификаторов классифицирует правильно примерно половину точек. Можно сделать вывод, что в этом случае верно классифицируются разные точки.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is my result equal to standard:\n",
      "0.849040867389\n"
     ]
    }
   ],
   "source": [
    "compare = np.array(test1) == np.array(test2)\n",
    "right = 1. / len(x_test) * np.sum(compare)\n",
    "print 'is my result equal to standard:'\n",
    "print right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим качество работы написанного классификатора на тестовой выборке. Результаты разные, но в подавляющем большинстве случаев верно классифицируется более 50% точек. В среднем этот процент достаточно высок: 70 - 80%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is my result equal to expected:\n",
      "0.666388657214\n"
     ]
    }
   ],
   "source": [
    "compare = np.array(test1) == np.array(y_test)\n",
    "right = 1. / len(x_test) * np.sum(compare)\n",
    "print 'is my result equal to expected:'\n",
    "print right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим качество работы стандартного классификатора на тестовой выборке. Результаты также различаются, при этом процент верно классифицированных точек может быть ниже, чем при использовании написанного классификатора. Но в среднем он дает примерно такой же процент: 70-80%.\n",
    "То, что иногда лучше работает написанный классификатор, а иногда стандартный, причем разница не в 3-5 процентов, а гораздо больше: 20-30, можно объяснить различиями в реализации метода fit()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is standard result equal to expected:\n",
      "0.532110091743\n"
     ]
    }
   ],
   "source": [
    "compare = np.array(y_test) == np.array(test2)\n",
    "right = 1. / len(x_test) * np.sum(compare)\n",
    "print 'is standard result equal to expected:'\n",
    "print right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# График\n",
    "Нарисуем график, где обозначим точки из первой группы желтым, точки из второй группы - красным, разделяющую прямую - синим."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD8CAYAAACVZ8iyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xdbe2668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf1.graph2D(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Размер шага\n",
    "При обучении использовался шаг c / t, где t - номер итерации, c = const > 0 (c = 0.5). Таким образом, чем больше итераций мы сделаем, тем меньше будет шаг, что увеличивает вероятность того, что мы не \"проскочим\" искомую точку. В то же время если бы шаг был маленьким изначально, то для получения ответа с достаточной точностью потребовалось бы очень много итераций. Поэтому такой размер шага кажется оптимальным. Узнаем, какой количество итераций потребовалось, чтобы обучить выборку с использованием шага c / t.\n",
    "Количество итераций для точности epsilon = 0.05 в среднем составляет около 180-200.<br>\n",
    "Теперь попробуем поменять шаг на константу. Результатов обучения при таких условиях и при больших значениях констант (я пробовала значения констант 0.01, 0.1, 0.5, 1, 10) я так и не дождалась (видимо, заданная точность никогда не достигалась, потому что алгоритм просто перескакивал через искомую точку), а при маленьких значениях (например, 0.0005) алгоритм слишком рано заканчивал работу (нужная точность достигалась практически сразу, потому что шаг в сторону антиградиента делался очень маленький), поэтому результат оказывался совесм не таким, каким должен был.<br>\n",
    "Попробуем взять менее быстро растующие, чем y = x, функции, и более быстро растущие.\n",
    "Шаг c / ln(t): ln(x) растет медленне, чем x. Результатов я тоже не дождалась, но, наблюдая за изменением вектора w на каждом шаге, можено было сделать вывод, что сходимость есть, но очень медленная.<br>\n",
    "Шаг c / sqrt(t): sqrt(x) тоже растет медленнее, чем x. Как и в случае с логарифмом: очень медленная сходимость.\n",
    "Шаг c / t^2: x^2 растет быстрее, чем x. Тоже оказался неподходящим, потому что, как и в случае константы, в некоторых случаях нужная точность достигалась слишком рано (шаг маленький).\n",
    "Таким образом, оптимальный размер шага: c / t.\n",
    "Подберем оптимальную константу.\n",
    "c = 1: итераций около 500\n",
    "с = 0.5: итераций около 200\n",
    "c = 0.1: итераций < 100, но результат плохой\n",
    "c = 2: итераций около 500\n",
    "с = 5: итераций > 1000\n",
    "Таким образом, оставляем шаг 0.5 / t."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262\n"
     ]
    }
   ],
   "source": [
    "print clf1.get_iter_count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
